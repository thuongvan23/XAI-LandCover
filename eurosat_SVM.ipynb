{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thuongvan23/XAI-LandCover/blob/kienNB/eurosat_SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da7f2af0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da7f2af0",
        "outputId": "0de8bfc9-c848-489a-b0be-d25f4617533e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# 1. Mount Google Drive vÃ  cÃ i Ä‘áº·t thÆ° viá»‡n\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install -q kaggle tifffile rasterio torch torchvision scikit-learn pandas numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b8d5658",
      "metadata": {
        "id": "9b8d5658"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 2. Cáº¥u hÃ¬nh kaggle.json Ä‘á»ƒ táº£i dataset\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp \"/content/drive/MyDrive/Colab Notebooks/kaggle.json\" ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d776ff3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d776ff3",
        "outputId": "ce7cc26b-afba-4ec4-d5b1-9ae57302c763"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/apollo2506/eurosat-dataset\n",
            "License(s): CC0-1.0\n",
            "Downloading eurosat-dataset.zip to /content\n",
            " 99% 2.02G/2.04G [00:18<00:01, 16.9MB/s]\n",
            "100% 2.04G/2.04G [00:18<00:00, 120MB/s] \n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 3. Táº£i vÃ  giáº£i nÃ©n dataset EuroSat\n",
        "!kaggle datasets download -d apollo2506/eurosat-dataset\n",
        "!unzip -q eurosat-dataset.zip -d ./eurosat_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c1bbc35",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c1bbc35",
        "outputId": "760c3af9-22af-43b9-91ee-a605c5a6da67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EuroSATallBands/\n",
            "  test.csv\n",
            "  validation.csv\n",
            "  label_map.json\n",
            "  train.csv\n",
            "  Industrial/\n",
            "    Industrial_2499.tif\n",
            "    Industrial_1893.tif\n",
            "    Industrial_327.tif\n",
            "    Industrial_928.tif\n",
            "    Industrial_58.tif\n",
            "  Residential/\n",
            "    Residential_2678.tif\n",
            "    Residential_2937.tif\n",
            "    Residential_1563.tif\n",
            "    Residential_2032.tif\n",
            "    Residential_1486.tif\n",
            "  AnnualCrop/\n",
            "    AnnualCrop_1606.tif\n",
            "    AnnualCrop_325.tif\n",
            "    AnnualCrop_1185.tif\n",
            "    AnnualCrop_2415.tif\n",
            "    AnnualCrop_266.tif\n",
            "  SeaLake/\n",
            "    SeaLake_1971.tif\n",
            "    SeaLake_2675.tif\n",
            "    SeaLake_2896.tif\n",
            "    SeaLake_2215.tif\n",
            "    SeaLake_1093.tif\n",
            "  Pasture/\n",
            "    Pasture_1368.tif\n",
            "    Pasture_209.tif\n",
            "    Pasture_1953.tif\n",
            "    Pasture_1732.tif\n",
            "    Pasture_1415.tif\n",
            "  River/\n",
            "    River_1206.tif\n",
            "    River_2370.tif\n",
            "    River_274.tif\n",
            "    River_2466.tif\n",
            "    River_624.tif\n",
            "  PermanentCrop/\n",
            "    PermanentCrop_2412.tif\n",
            "    PermanentCrop_1797.tif\n",
            "    PermanentCrop_31.tif\n",
            "    PermanentCrop_2158.tif\n",
            "    PermanentCrop_562.tif\n",
            "  HerbaceousVegetation/\n",
            "    HerbaceousVegetation_1534.tif\n",
            "    HerbaceousVegetation_2351.tif\n",
            "    HerbaceousVegetation_1171.tif\n",
            "    HerbaceousVegetation_2688.tif\n",
            "    HerbaceousVegetation_780.tif\n",
            "  Highway/\n",
            "    Highway_1011.tif\n",
            "    Highway_2243.tif\n",
            "    Highway_2446.tif\n",
            "    Highway_68.tif\n",
            "    Highway_1343.tif\n",
            "  Forest/\n",
            "    Forest_2827.tif\n",
            "    Forest_2029.tif\n",
            "    Forest_2572.tif\n",
            "    Forest_2055.tif\n",
            "    Forest_2013.tif\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 4. Kiá»ƒm tra cáº¥u trÃºc thÆ° má»¥c vÃ  má»™t vÃ i file\n",
        "import os\n",
        "root_dir = \"/content/eurosat_data/EuroSATallBands\"\n",
        "for root, dirs, files in os.walk(root_dir):\n",
        "    level = root.replace(root_dir, '').count(os.sep)\n",
        "    indent = ' ' * 2 * level\n",
        "    print(f\"{indent}{os.path.basename(root)}/\")\n",
        "    subindent = ' ' * 2 * (level + 1)\n",
        "    for f in files[:5]:\n",
        "        print(f\"{subindent}{f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f6a8a57",
      "metadata": {
        "id": "9f6a8a57"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 5. Dataset class Ä‘á»c áº£nh .tif 13 channels vÃ  csv cÃ³ label\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import rasterio\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class EuroSATAllBands(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        img_path = os.path.join(self.root_dir, row['Filename'])\n",
        "        label = int(row['Label'])\n",
        "\n",
        "        with rasterio.open(img_path) as src:\n",
        "            img = src.read().astype(np.float32)  # (13, H, W)\n",
        "            img /= 10000.0  # Normalize\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26a6beda",
      "metadata": {
        "id": "26a6beda"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 6. Chuyá»ƒn áº£nh numpy sang tensor\n",
        "def to_tensor_13(img):\n",
        "    return torch.tensor(img, dtype=torch.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f963bc3c",
      "metadata": {
        "id": "f963bc3c"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 7. ResNet18 sá»­a Ä‘áº§u vÃ o 13 channels, loáº¡i bá» fully connected cuá»‘i\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "def get_resnet13():\n",
        "    model = resnet18(pretrained=False)\n",
        "    model.conv1 = nn.Conv2d(13, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "    model.fc = nn.Identity()\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "626ade5f",
      "metadata": {
        "id": "626ade5f"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 8. HÃ m trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng báº±ng model\n",
        "import numpy as np\n",
        "\n",
        "def extract_features(model, dataloader, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    features, labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, lbls in dataloader:\n",
        "            imgs = imgs.to(device)\n",
        "            feats = model(imgs).cpu().numpy()\n",
        "            features.append(feats)\n",
        "            labels.append(lbls.numpy())\n",
        "\n",
        "    return np.vstack(features), np.concatenate(labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef4dc2d8",
      "metadata": {
        "id": "ef4dc2d8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 9. Chuáº©n bá»‹ DataLoader cho train/val/test\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "base_path = \"/content/eurosat_data/EuroSATallBands\"\n",
        "\n",
        "train_dataset = EuroSATAllBands(csv_file=os.path.join(base_path, \"train.csv\"),\n",
        "                               root_dir=base_path,\n",
        "                               transform=to_tensor_13)\n",
        "\n",
        "val_dataset = EuroSATAllBands(csv_file=os.path.join(base_path, \"validation.csv\"),\n",
        "                             root_dir=base_path,\n",
        "                             transform=to_tensor_13)\n",
        "\n",
        "test_dataset = EuroSATAllBands(csv_file=os.path.join(base_path, \"test.csv\"),\n",
        "                              root_dir=base_path,\n",
        "                              transform=to_tensor_13)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0029e5a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0029e5a",
        "outputId": "1de14b00-ecfd-443e-fb52-897489e6200d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ” Extracting features...\n",
            "ğŸ“ Training SVM...\n",
            "âœ… Train Accuracy: 0.8376\n",
            "âœ… Validation Accuracy: 0.8123\n",
            "âœ… Test Accuracy: 0.8249\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 10. TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng vÃ  huáº¥n luyá»‡n SVM\n",
        "import torch\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "resnet = get_resnet13()\n",
        "\n",
        "print(\"ğŸ” Extracting features...\")\n",
        "X_train, y_train = extract_features(resnet, train_loader, device)\n",
        "X_val, y_val = extract_features(resnet, val_loader, device)\n",
        "X_test, y_test = extract_features(resnet, test_loader, device)\n",
        "\n",
        "print(\"ğŸ“ Training SVM...\")\n",
        "svm = SVC(kernel='rbf', C=10, gamma='scale')\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "train_acc = accuracy_score(y_train, svm.predict(X_train))\n",
        "val_acc = accuracy_score(y_val, svm.predict(X_val))\n",
        "test_acc = accuracy_score(y_test, svm.predict(X_test))\n",
        "\n",
        "print(f\"âœ… Train Accuracy: {train_acc:.4f}\")\n",
        "print(f\"âœ… Validation Accuracy: {val_acc:.4f}\")\n",
        "print(f\"âœ… Test Accuracy: {test_acc:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}